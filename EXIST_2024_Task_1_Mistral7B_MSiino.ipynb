{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/marco-siino/EXIST2024/blob/main/EXIST_2024_Task_1_Mistral7B_MSiino.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_ubSCVmmlBKX"
      },
      "source": [
        "Installing dependencies. You might need to tweak the CMAKE_ARGS for the `llama-cpp-python` pip package."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CKL68Itp9Bm-",
        "outputId": "ff876f14-7993-4d76-b5f8-79836dd2acd1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting llama-cpp-python>=0.1.79\n",
            "  Downloading llama_cpp_python-0.2.71.tar.gz (48.4 MB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m48.4/48.4 MB\u001b[0m \u001b[31m173.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting typing-extensions>=4.5.0 (from llama-cpp-python>=0.1.79)\n",
            "  Downloading typing_extensions-4.11.0-py3-none-any.whl (34 kB)\n",
            "Collecting numpy>=1.20.0 (from llama-cpp-python>=0.1.79)\n",
            "  Downloading numpy-1.26.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.2 MB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m18.2/18.2 MB\u001b[0m \u001b[31m192.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting diskcache>=5.6.1 (from llama-cpp-python>=0.1.79)\n",
            "  Downloading diskcache-5.6.3-py3-none-any.whl (45 kB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m45.5/45.5 kB\u001b[0m \u001b[31m176.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting jinja2>=2.11.3 (from llama-cpp-python>=0.1.79)\n",
            "  Downloading jinja2-3.1.4-py3-none-any.whl (133 kB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m133.3/133.3 kB\u001b[0m \u001b[31m210.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting MarkupSafe>=2.0 (from jinja2>=2.11.3->llama-cpp-python>=0.1.79)\n",
            "  Downloading MarkupSafe-2.1.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (25 kB)\n",
            "Building wheels for collected packages: llama-cpp-python\n",
            "  Building wheel for llama-cpp-python (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for llama-cpp-python: filename=llama_cpp_python-0.2.71-cp310-cp310-linux_x86_64.whl size=55332750 sha256=d976022a19ae95f0de4f306688a912d23a87fc5ea7a1eb5d876f6c3f25880789\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-7oc3mfnv/wheels/5d/35/d3/b4ab42b4528cc5e1f9b1469c4b4076de51e2f3ceb50506b424\n",
            "Successfully built llama-cpp-python\n",
            "Installing collected packages: typing-extensions, numpy, MarkupSafe, diskcache, jinja2, llama-cpp-python\n",
            "  Attempting uninstall: typing-extensions\n",
            "    Found existing installation: typing_extensions 4.11.0\n",
            "    Uninstalling typing_extensions-4.11.0:\n",
            "      Successfully uninstalled typing_extensions-4.11.0\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.25.2\n",
            "    Uninstalling numpy-1.25.2:\n",
            "      Successfully uninstalled numpy-1.25.2\n",
            "  Attempting uninstall: MarkupSafe\n",
            "    Found existing installation: MarkupSafe 2.1.5\n",
            "    Uninstalling MarkupSafe-2.1.5:\n",
            "      Successfully uninstalled MarkupSafe-2.1.5\n",
            "  Attempting uninstall: jinja2\n",
            "    Found existing installation: Jinja2 3.1.3\n",
            "    Uninstalling Jinja2-3.1.3:\n",
            "      Successfully uninstalled Jinja2-3.1.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torch 2.2.1+cu121 requires nvidia-cublas-cu12==12.1.3.1; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n",
            "torch 2.2.1+cu121 requires nvidia-cuda-cupti-cu12==12.1.105; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n",
            "torch 2.2.1+cu121 requires nvidia-cuda-nvrtc-cu12==12.1.105; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n",
            "torch 2.2.1+cu121 requires nvidia-cuda-runtime-cu12==12.1.105; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n",
            "torch 2.2.1+cu121 requires nvidia-cudnn-cu12==8.9.2.26; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n",
            "torch 2.2.1+cu121 requires nvidia-cufft-cu12==11.0.2.54; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n",
            "torch 2.2.1+cu121 requires nvidia-curand-cu12==10.3.2.106; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n",
            "torch 2.2.1+cu121 requires nvidia-cusolver-cu12==11.4.5.107; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n",
            "torch 2.2.1+cu121 requires nvidia-cusparse-cu12==12.1.0.106; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n",
            "torch 2.2.1+cu121 requires nvidia-nccl-cu12==2.19.3; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n",
            "torch 2.2.1+cu121 requires nvidia-nvtx-cu12==12.1.105; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed MarkupSafe-2.1.5 diskcache-5.6.3 jinja2-3.1.4 llama-cpp-python-0.2.71 numpy-1.26.4 typing-extensions-4.11.0\n",
            "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.10/dist-packages (0.20.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (3.14.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (2023.6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (4.66.4)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (6.0.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (4.11.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (24.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (2024.2.2)\n",
            "Collecting datasets\n",
            "  Downloading datasets-2.19.1-py3-none-any.whl (542 kB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m542.0/542.0 kB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.14.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.26.4)\n",
            "Requirement already satisfied: pyarrow>=12.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (14.0.2)\n",
            "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets) (0.6)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.0.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.4)\n",
            "Collecting xxhash (from datasets)\n",
            "  Downloading xxhash-3.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting multiprocess (from datasets)\n",
            "  Downloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fsspec[http]<=2024.3.1,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.9.5)\n",
            "Collecting huggingface-hub>=0.21.2 (from datasets)\n",
            "  Downloading huggingface_hub-0.23.0-py3-none-any.whl (401 kB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m401.2/401.2 kB\u001b[0m \u001b[31m17.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (24.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.2->datasets) (4.11.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2024.2.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
            "Installing collected packages: xxhash, dill, multiprocess, huggingface-hub, datasets\n",
            "  Attempting uninstall: huggingface-hub\n",
            "    Found existing installation: huggingface-hub 0.20.3\n",
            "    Uninstalling huggingface-hub-0.20.3:\n",
            "      Successfully uninstalled huggingface-hub-0.20.3\n",
            "Successfully installed datasets-2.19.1 dill-0.3.8 huggingface-hub-0.23.0 multiprocess-0.70.16 xxhash-3.4.1\n",
            "Collecting deep-translator\n",
            "  Downloading deep_translator-1.11.4-py3-none-any.whl (42 kB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m42.3/42.3 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: beautifulsoup4<5.0.0,>=4.9.1 in /usr/local/lib/python3.10/dist-packages (from deep-translator) (4.12.3)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.23.0 in /usr/local/lib/python3.10/dist-packages (from deep-translator) (2.31.0)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4<5.0.0,>=4.9.1->deep-translator) (2.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.23.0->deep-translator) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.23.0->deep-translator) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.23.0->deep-translator) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.23.0->deep-translator) (2024.2.2)\n",
            "Installing collected packages: deep-translator\n",
            "Successfully installed deep-translator-1.11.4\n"
          ]
        }
      ],
      "source": [
        "# GPU llama-cpp-python; Starting from version llama-cpp-python==0.1.79, it supports GGUF\n",
        "!CMAKE_ARGS=\"-DLLAMA_CUBLAS=on \" pip install 'llama-cpp-python>=0.1.79' --force-reinstall --upgrade --no-cache-dir\n",
        "# For download the models\n",
        "!pip install huggingface_hub\n",
        "!pip install datasets\n",
        "!pip install -U deep-translator\n",
        "\n",
        "import datasets\n",
        "from datasets import load_dataset\n",
        "from deep_translator import GoogleTranslator\n",
        "import json\n",
        "import re\n",
        "import random\n",
        "import numpy as np\n",
        "import tqdm.notebook as tqdm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M2ns57iDlBKa"
      },
      "source": [
        "Downloading an instruction-finetuned Mistral model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "uDMqQmBfAhYO",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "2f9ce44597fd4605ae80a651595427b8",
            "e3b28ef3d43f485eab6249e38bce939d",
            "422514713b674c6fa08e3ccfec13d587",
            "f1af885bd06a414194141b2b4caba3c5",
            "bcd7b0cb09fd4011817744131ed5786b",
            "ecc8fceff5be4c74a8e8078c30a0537e",
            "066a845b3b494ffc86eaf3b42f4f1be8",
            "8a17530926d34ebc81cf106d8a1a1892",
            "ee360156296d477ead496a7516f8c40b",
            "00742ad8442849b7884fc2771237645e",
            "4fd3deff3d1f40b693b7c2722c1cc959"
          ]
        },
        "outputId": "d7438c44-9af1-48fc-eebc-4a417f642628"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "mistral-7b-instruct-v0.2.Q6_K.gguf:   0%|          | 0.00/5.94G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2f9ce44597fd4605ae80a651595427b8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "llama_model_loader: loaded meta data with 24 key-value pairs and 291 tensors from /root/.cache/huggingface/hub/models--TheBloke--Mistral-7B-Instruct-v0.2-GGUF/snapshots/3a6fbf4a41a1d52e415a4958cde6856d34b2db93/mistral-7b-instruct-v0.2.Q6_K.gguf (version GGUF V3 (latest))\n",
            "llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.\n",
            "llama_model_loader: - kv   0:                       general.architecture str              = llama\n",
            "llama_model_loader: - kv   1:                               general.name str              = mistralai_mistral-7b-instruct-v0.2\n",
            "llama_model_loader: - kv   2:                       llama.context_length u32              = 32768\n",
            "llama_model_loader: - kv   3:                     llama.embedding_length u32              = 4096\n",
            "llama_model_loader: - kv   4:                          llama.block_count u32              = 32\n",
            "llama_model_loader: - kv   5:                  llama.feed_forward_length u32              = 14336\n",
            "llama_model_loader: - kv   6:                 llama.rope.dimension_count u32              = 128\n",
            "llama_model_loader: - kv   7:                 llama.attention.head_count u32              = 32\n",
            "llama_model_loader: - kv   8:              llama.attention.head_count_kv u32              = 8\n",
            "llama_model_loader: - kv   9:     llama.attention.layer_norm_rms_epsilon f32              = 0.000010\n",
            "llama_model_loader: - kv  10:                       llama.rope.freq_base f32              = 1000000.000000\n",
            "llama_model_loader: - kv  11:                          general.file_type u32              = 18\n",
            "llama_model_loader: - kv  12:                       tokenizer.ggml.model str              = llama\n",
            "llama_model_loader: - kv  13:                      tokenizer.ggml.tokens arr[str,32000]   = [\"<unk>\", \"<s>\", \"</s>\", \"<0x00>\", \"<...\n",
            "llama_model_loader: - kv  14:                      tokenizer.ggml.scores arr[f32,32000]   = [0.000000, 0.000000, 0.000000, 0.0000...\n",
            "llama_model_loader: - kv  15:                  tokenizer.ggml.token_type arr[i32,32000]   = [2, 3, 3, 6, 6, 6, 6, 6, 6, 6, 6, 6, ...\n",
            "llama_model_loader: - kv  16:                tokenizer.ggml.bos_token_id u32              = 1\n",
            "llama_model_loader: - kv  17:                tokenizer.ggml.eos_token_id u32              = 2\n",
            "llama_model_loader: - kv  18:            tokenizer.ggml.unknown_token_id u32              = 0\n",
            "llama_model_loader: - kv  19:            tokenizer.ggml.padding_token_id u32              = 0\n",
            "llama_model_loader: - kv  20:               tokenizer.ggml.add_bos_token bool             = true\n",
            "llama_model_loader: - kv  21:               tokenizer.ggml.add_eos_token bool             = false\n",
            "llama_model_loader: - kv  22:                    tokenizer.chat_template str              = {{ bos_token }}{% for message in mess...\n",
            "llama_model_loader: - kv  23:               general.quantization_version u32              = 2\n",
            "llama_model_loader: - type  f32:   65 tensors\n",
            "llama_model_loader: - type q6_K:  226 tensors\n",
            "llm_load_vocab: special tokens definition check successful ( 259/32000 ).\n",
            "llm_load_print_meta: format           = GGUF V3 (latest)\n",
            "llm_load_print_meta: arch             = llama\n",
            "llm_load_print_meta: vocab type       = SPM\n",
            "llm_load_print_meta: n_vocab          = 32000\n",
            "llm_load_print_meta: n_merges         = 0\n",
            "llm_load_print_meta: n_ctx_train      = 32768\n",
            "llm_load_print_meta: n_embd           = 4096\n",
            "llm_load_print_meta: n_head           = 32\n",
            "llm_load_print_meta: n_head_kv        = 8\n",
            "llm_load_print_meta: n_layer          = 32\n",
            "llm_load_print_meta: n_rot            = 128\n",
            "llm_load_print_meta: n_embd_head_k    = 128\n",
            "llm_load_print_meta: n_embd_head_v    = 128\n",
            "llm_load_print_meta: n_gqa            = 4\n",
            "llm_load_print_meta: n_embd_k_gqa     = 1024\n",
            "llm_load_print_meta: n_embd_v_gqa     = 1024\n",
            "llm_load_print_meta: f_norm_eps       = 0.0e+00\n",
            "llm_load_print_meta: f_norm_rms_eps   = 1.0e-05\n",
            "llm_load_print_meta: f_clamp_kqv      = 0.0e+00\n",
            "llm_load_print_meta: f_max_alibi_bias = 0.0e+00\n",
            "llm_load_print_meta: f_logit_scale    = 0.0e+00\n",
            "llm_load_print_meta: n_ff             = 14336\n",
            "llm_load_print_meta: n_expert         = 0\n",
            "llm_load_print_meta: n_expert_used    = 0\n",
            "llm_load_print_meta: causal attn      = 1\n",
            "llm_load_print_meta: pooling type     = 0\n",
            "llm_load_print_meta: rope type        = 0\n",
            "llm_load_print_meta: rope scaling     = linear\n",
            "llm_load_print_meta: freq_base_train  = 1000000.0\n",
            "llm_load_print_meta: freq_scale_train = 1\n",
            "llm_load_print_meta: n_yarn_orig_ctx  = 32768\n",
            "llm_load_print_meta: rope_finetuned   = unknown\n",
            "llm_load_print_meta: ssm_d_conv       = 0\n",
            "llm_load_print_meta: ssm_d_inner      = 0\n",
            "llm_load_print_meta: ssm_d_state      = 0\n",
            "llm_load_print_meta: ssm_dt_rank      = 0\n",
            "llm_load_print_meta: model type       = 8B\n",
            "llm_load_print_meta: model ftype      = Q6_K\n",
            "llm_load_print_meta: model params     = 7.24 B\n",
            "llm_load_print_meta: model size       = 5.53 GiB (6.56 BPW) \n",
            "llm_load_print_meta: general.name     = mistralai_mistral-7b-instruct-v0.2\n",
            "llm_load_print_meta: BOS token        = 1 '<s>'\n",
            "llm_load_print_meta: EOS token        = 2 '</s>'\n",
            "llm_load_print_meta: UNK token        = 0 '<unk>'\n",
            "llm_load_print_meta: PAD token        = 0 '<unk>'\n",
            "llm_load_print_meta: LF token         = 13 '<0x0A>'\n",
            "llm_load_tensors: ggml ctx size =    0.30 MiB\n",
            "llm_load_tensors: offloading 32 repeating layers to GPU\n",
            "llm_load_tensors: offloaded 32/33 layers to GPU\n",
            "llm_load_tensors:        CPU buffer size =  5666.09 MiB\n",
            "llm_load_tensors:      CUDA0 buffer size =  5461.00 MiB\n",
            "...................................................................................................\n",
            "llama_new_context_with_model: n_ctx      = 8192\n",
            "llama_new_context_with_model: n_batch    = 800\n",
            "llama_new_context_with_model: n_ubatch   = 512\n",
            "llama_new_context_with_model: flash_attn = 0\n",
            "llama_new_context_with_model: freq_base  = 1000000.0\n",
            "llama_new_context_with_model: freq_scale = 1\n",
            "llama_kv_cache_init:      CUDA0 KV buffer size =  1024.00 MiB\n",
            "llama_new_context_with_model: KV self size  = 1024.00 MiB, K (f16):  512.00 MiB, V (f16):  512.00 MiB\n",
            "llama_new_context_with_model:  CUDA_Host  output buffer size =     0.12 MiB\n",
            "llama_new_context_with_model:      CUDA0 compute buffer size =   560.00 MiB\n",
            "llama_new_context_with_model:  CUDA_Host compute buffer size =    24.01 MiB\n",
            "llama_new_context_with_model: graph nodes  = 1030\n",
            "llama_new_context_with_model: graph splits = 4\n",
            "AVX = 1 | AVX_VNNI = 0 | AVX2 = 1 | AVX512 = 1 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | FMA = 1 | NEON = 0 | ARM_FMA = 0 | F16C = 1 | FP16_VA = 0 | WASM_SIMD = 0 | BLAS = 1 | SSE3 = 1 | SSSE3 = 1 | VSX = 0 | MATMUL_INT8 = 0 | LLAMAFILE = 1 | \n",
            "Model metadata: {'tokenizer.chat_template': \"{{ bos_token }}{% for message in messages %}{% if (message['role'] == 'user') != (loop.index0 % 2 == 0) %}{{ raise_exception('Conversation roles must alternate user/assistant/user/assistant/...') }}{% endif %}{% if message['role'] == 'user' %}{{ '[INST] ' + message['content'] + ' [/INST]' }}{% elif message['role'] == 'assistant' %}{{ message['content'] + eos_token}}{% else %}{{ raise_exception('Only user and assistant roles are supported!') }}{% endif %}{% endfor %}\", 'tokenizer.ggml.add_eos_token': 'false', 'tokenizer.ggml.padding_token_id': '0', 'tokenizer.ggml.unknown_token_id': '0', 'tokenizer.ggml.eos_token_id': '2', 'general.architecture': 'llama', 'llama.rope.freq_base': '1000000.000000', 'llama.context_length': '32768', 'general.name': 'mistralai_mistral-7b-instruct-v0.2', 'tokenizer.ggml.add_bos_token': 'true', 'llama.embedding_length': '4096', 'llama.feed_forward_length': '14336', 'llama.attention.layer_norm_rms_epsilon': '0.000010', 'llama.rope.dimension_count': '128', 'tokenizer.ggml.bos_token_id': '1', 'llama.attention.head_count': '32', 'llama.block_count': '32', 'llama.attention.head_count_kv': '8', 'general.quantization_version': '2', 'tokenizer.ggml.model': 'llama', 'general.file_type': '18'}\n",
            "Guessed chat format: mistral-instruct\n"
          ]
        }
      ],
      "source": [
        "from huggingface_hub import hf_hub_download\n",
        "\n",
        "model_name_or_path = \"TheBloke/Mistral-7B-Instruct-v0.2-GGUF\"\n",
        "model_basename = \"mistral-7b-instruct-v0.2.Q6_K.gguf\"\n",
        "\n",
        "model_path = hf_hub_download(repo_id=model_name_or_path, filename=model_basename)\n",
        "\n",
        "# This config has been tested on an RTX 3080 (VRAM of 16GB).\n",
        "# you might need to tweak with respect to your hardware.\n",
        "from llama_cpp import Llama\n",
        "lcpp_llm = Llama(\n",
        "    model_path=model_path,\n",
        "    n_threads=4, #16, # CPU cores\n",
        "    n_batch=800, #8000, # Should be between 1 and n_ctx, consider the amount of VRAM in your GPU.\n",
        "    n_gpu_layers=32, # Change this value based on your model and your GPU VRAM pool.\n",
        "    n_ctx=8192, # Context window\n",
        "    logits_all=True\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Download the dataset for the three subtasks."
      ],
      "metadata": {
        "id": "jeXgLOpd4ztp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Subtask 1.\n",
        "!wget 'https://raw.githubusercontent.com/marco-siino/EXIST2024/main/dataset/EXIST2023_test_clean.json'\n",
        "!wget 'https://raw.githubusercontent.com/marco-siino/EXIST2024/main/dataset/EXIST2024_training.json'\n",
        "!wget 'https://raw.githubusercontent.com/marco-siino/EXIST2024/main/dataset/EXIST2024_training_task1_gold_hard.json'\n",
        "\n",
        "\n",
        "train_path = 'EXIST2024_training.json'\n",
        "train_gold_path = 'EXIST2024_training_task1_gold_hard.json'\n",
        "test_path = 'EXIST2023_test_clean.json'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fKaC_tQ-2xbI",
        "outputId": "72e770b9-9b47-4b98-b00c-0a965009ea83"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-05-09 10:33:51--  https://raw.githubusercontent.com/marco-siino/EXIST2024/main/dataset/EXIST2023_test_clean.json\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2143912 (2.0M) [text/plain]\n",
            "Saving to: ‚ÄòEXIST2023_test_clean.json‚Äô\n",
            "\n",
            "EXIST2023_test_clea 100%[===================>]   2.04M  --.-KB/s    in 0.02s   \n",
            "\n",
            "2024-05-09 10:33:51 (87.2 MB/s) - ‚ÄòEXIST2023_test_clean.json‚Äô saved [2143912/2143912]\n",
            "\n",
            "--2024-05-09 10:33:51--  https://raw.githubusercontent.com/marco-siino/EXIST2024/main/dataset/EXIST2024_training.json\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.109.133, 185.199.108.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 9397366 (9.0M) [text/plain]\n",
            "Saving to: ‚ÄòEXIST2024_training.json‚Äô\n",
            "\n",
            "EXIST2024_training. 100%[===================>]   8.96M  --.-KB/s    in 0.04s   \n",
            "\n",
            "2024-05-09 10:33:52 (210 MB/s) - ‚ÄòEXIST2024_training.json‚Äô saved [9397366/9397366]\n",
            "\n",
            "--2024-05-09 10:33:52--  https://raw.githubusercontent.com/marco-siino/EXIST2024/main/dataset/EXIST2024_training_task1_gold_hard.json\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 433241 (423K) [text/plain]\n",
            "Saving to: ‚ÄòEXIST2024_training_task1_gold_hard.json‚Äô\n",
            "\n",
            "EXIST2024_training_ 100%[===================>] 423.09K  --.-KB/s    in 0.01s   \n",
            "\n",
            "2024-05-09 10:33:52 (32.7 MB/s) - ‚ÄòEXIST2024_training_task1_gold_hard.json‚Äô saved [433241/433241]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create few-shot samples from training and validation set."
      ],
      "metadata": {
        "id": "fHPX3E0PCJ9q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        " prompt_context = \"<s>[INST] Is the following TWEET sexist, in any form, or does it describe situations in which such discrimination occurs (i.e., it is sexist itself, describes a sexist situation or criticizes a sexist behaviour)? Reply only with YES or NO.\\n\"\n"
      ],
      "metadata": {
        "id": "zafRW5vU6y1n"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_few_shot_samples_task1(json_set_path,nr_samples):\n",
        "\n",
        "  nr_few_shot_samples = nr_samples\n",
        "\n",
        "  few_shot_counter = 0\n",
        "\n",
        "  few_shot_samples = ''\n",
        "\n",
        "  with open(train_gold_path, 'r') as istr:\n",
        "    train_gold_json = json.load(istr)\n",
        "  indexed_data = {entry[\"id\"]: entry for entry in train_gold_json}\n",
        "  #print(indexed_data['100001'])\n",
        "  with open(json_set_path, 'r') as istr:\n",
        "    train_1_json = json.load(istr)\n",
        "  #print(train_1_json[0])\n",
        "  for key, value in train_1_json.items():\n",
        "  #for i in tqdm.trange(len(train_1_json)):\n",
        "    if few_shot_counter == nr_few_shot_samples:\n",
        "      break\n",
        "\n",
        "\n",
        "    try:\n",
        "      label = indexed_data[key]['value']\n",
        "    except:\n",
        "      continue\n",
        "    #for sentence_nr in range(0,len(train_1_json[i]['speakers'])):\n",
        "    few_shot_counter+=1\n",
        "    tweet = train_1_json[key]['tweet']\n",
        "    print(train_1_json[key]['tweet'] + ' // ' + label)\n",
        "    if train_1_json[key]['lang']=='es':\n",
        "      tweet = GoogleTranslator(source='es', target='en').translate(train_1_json[key]['tweet'])\n",
        "\n",
        "    few_shot_samples += prompt_context+\"TWEET:\"+tweet + ' [/INST] \\n ' + label + \"\\n</s> \\n\\n \"\n",
        "\n",
        "    if few_shot_counter == nr_few_shot_samples:\n",
        "        break\n",
        "\n",
        "  return few_shot_samples"
      ],
      "metadata": {
        "id": "99ag8gav51mC"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "few_shot_samples = create_few_shot_samples_task1(train_path,10)\n",
        "#few_shot_samples += create_few_shot_samples_task1(val_path_1,80)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o8IaDH-7GmrN",
        "outputId": "f23eb768-e9bc-4901-ce9b-d43dcaa76527"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "@TheChiflis Ignora al otro, es un capullo.El problema con este youtuber denuncia el acoso... cuando no afecta a la gente de izquierdas. Por ejemplo, en su video sobre el gamergate presenta como \"normal\" el acoso que reciben Fisher, Anita o Z√∂ey cuando hubo hasta amenazas de bomba. // YES\n",
            "@ultimonomada_ Si comicsgate se parece en algo a gamergate pues muy bien por el acoso. Y si se est√° haciendo un sabotaje porque hay personajes que no os gustan entonces gracias por darme la raz√≥n. Sois unos lloricas ofendidos. // NO\n",
            "@Steven2897 Lee sobre Gamergate, y como eso ha cambiado la manera en la cual nos comunicamos en el internet. Los fanboys de Halo est√°n t√≥xicos pero los fanboys de otras comunidades/juegos tambi√©n han querido coger pauta con eso ü§∑üèæ‚Äç‚ôÇÔ∏è // NO\n",
            "@novadragon21 @icep4ck @TvDannyZ Entonces como as√≠ es el mercado lo mejor no es hacer algo para cambiarlo y seguir alimentando el machismo en los consumidores en lugar apoyar a gente como las v√≠ctimas del gamergate.Acerca de lo otro, el \"ten√≠an\" implica un imperativo entonces no entiendo lo del buscaban. // YES\n",
            "@yonkykong Aaah s√≠. Andrew Dobson. El que se dedic√≥ a echar mierda del gamergate al m√°s puro estilo white knight, y todo deviantart se le ech√≥ encima // NO\n",
            "@BestKabest Esta gringa sigue llorando por el gamergate, que \"coincidencia\" que tenga pronombres en su perfil // YES\n",
            ".¬øConoces la #DECORACION #estilo #GAMER para #adolescentes  ?Te lo explicamos en nuestro #post : ‚ù§Ô∏è https://t.co/NuSNs36GIT¬øNos sigues?#inspiracionalcuadrado #interiorismo #homedecorideas #Madrid #chamberi #Salamanca #gamers #GAMERGATE #gamergirl https://t.co/Mcibiy8YdX // NO\n",
            "CES 2022 ASUS ROG Rise of Gamers Evento de lanzamiento https://t.co/CjqHQwxMFD #AMD2022 #AMD #AMDRedTeam #AMDRyzen #Intel #nvidia #NVIDIAOmniverse #NVIDIAGeForce #NVIDIAStudio #gamergirl #gamers #GamerGate #GamersUnite #gameroom #StockMarket #stocks #StocksToBuy #Stock // NO\n",
            "@Lorebrou16 @arrobaDonko Mierda, me siento vieja cuando dec√≠s Gamergate, que bardo .__.XD // NO\n",
            "@Recuenco @qlopdopis Bannon tiene tambi√©n historia.Aqu√≠ hablan de √©l, buen podcast, #16 - los ganadores de Gamergate https://t.co/nnfOHYhbrw // NO\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(few_shot_samples)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6WHgxqxAxcu1",
        "outputId": "e0ec2855-fc2b-4d96-c75d-e17167ae66bf"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<s>[INST] Is the following TWEET sexist, in any form, or does it describe situations in which such discrimination occurs (i.e., it is sexist itself, describes a sexist situation or criticizes a sexist behaviour)? Reply only with YES or NO.\n",
            "TWEET:@TheChiflis Ignore the other one, he's an idiot. The problem with this YouTuber is that he denounces harassment... when it doesn't affect people on the left. For example, in his video about gamergate he presents as \"normal\" the harassment that Fisher, Anita or Z√∂ey receive when there were even bomb threats. [/INST] \n",
            " YES\n",
            "</s> \n",
            "\n",
            " <s>[INST] Is the following TWEET sexist, in any form, or does it describe situations in which such discrimination occurs (i.e., it is sexist itself, describes a sexist situation or criticizes a sexist behaviour)? Reply only with YES or NO.\n",
            "TWEET:@ultimonomada_ If comicsgate is anything like gamergate, then good for the harassment. And if sabotage is being done because there are characters that you don't like, then thank you for agreeing with me. You are offended crybabies. [/INST] \n",
            " NO\n",
            "</s> \n",
            "\n",
            " <s>[INST] Is the following TWEET sexist, in any form, or does it describe situations in which such discrimination occurs (i.e., it is sexist itself, describes a sexist situation or criticizes a sexist behaviour)? Reply only with YES or NO.\n",
            "TWEET:@Steven2897 Read about Gamergate, and how it has changed the way we communicate on the internet. Halo fanboys are toxic but fanboys from other communities/games have also wanted to take a cue from that ü§∑üèæ‚Äç‚ôÇÔ∏è [/INST] \n",
            " NO\n",
            "</s> \n",
            "\n",
            " <s>[INST] Is the following TWEET sexist, in any form, or does it describe situations in which such discrimination occurs (i.e., it is sexist itself, describes a sexist situation or criticizes a sexist behaviour)? Reply only with YES or NO.\n",
            "TWEET:@novadragon21 @icep4ck @TvDannyZ So since this is the market, the best thing is not to do something to change it and continue feeding machismo in consumers instead of supporting people like the victims of gamergate. Regarding the other, the \"had\" implies a imperative then I don't understand what they were looking for. [/INST] \n",
            " YES\n",
            "</s> \n",
            "\n",
            " <s>[INST] Is the following TWEET sexist, in any form, or does it describe situations in which such discrimination occurs (i.e., it is sexist itself, describes a sexist situation or criticizes a sexist behaviour)? Reply only with YES or NO.\n",
            "TWEET:@yonkykong Aaah yes. Andrew Dobson. The one who dedicated himself to spouting gamergate shit in the purest white knight style, and all of deviantart fell on him [/INST] \n",
            " NO\n",
            "</s> \n",
            "\n",
            " <s>[INST] Is the following TWEET sexist, in any form, or does it describe situations in which such discrimination occurs (i.e., it is sexist itself, describes a sexist situation or criticizes a sexist behaviour)? Reply only with YES or NO.\n",
            "TWEET:@BestKabest This gringa is still crying about gamergate, what a \"coincidence\" that she has pronouns on her profile [/INST] \n",
            " YES\n",
            "</s> \n",
            "\n",
            " <s>[INST] Is the following TWEET sexist, in any form, or does it describe situations in which such discrimination occurs (i.e., it is sexist itself, describes a sexist situation or criticizes a sexist behaviour)? Reply only with YES or NO.\n",
            "TWEET:.Do you know the #GAMER #style #DECORATION for #teenagers? We explain it to you in our #post: ‚ù§Ô∏è https://t.co/NuSNs36GIT Are you following us? #inspiracionalcuadrado #interiorismo #homedecorideas #Madrid #chamberi #Salamanca #gamers #GAMERGATE #gamergirl https://t.co/Mcibiy8YdX [/INST] \n",
            " NO\n",
            "</s> \n",
            "\n",
            " <s>[INST] Is the following TWEET sexist, in any form, or does it describe situations in which such discrimination occurs (i.e., it is sexist itself, describes a sexist situation or criticizes a sexist behaviour)? Reply only with YES or NO.\n",
            "TWEET:CES 2022 ASUS ROG Rise of Gamers Launch Event https://t.co/CjqHQwxMFD #AMD2022 #AMD #AMDRedTeam #AMDRyzen #Intel #nvidia #NVIDIAOmniverse #NVIDIAGeForce #NVIDIAStudio #gamergirl #gamers #GamerGate #GamersUnite #gameroom #StockMarket # stocks #StocksToBuy #Stock [/INST] \n",
            " NO\n",
            "</s> \n",
            "\n",
            " <s>[INST] Is the following TWEET sexist, in any form, or does it describe situations in which such discrimination occurs (i.e., it is sexist itself, describes a sexist situation or criticizes a sexist behaviour)? Reply only with YES or NO.\n",
            "TWEET:@Lorebrou16 @arrobaDonko Shit, I feel old when you say Gamergate, what a bard .__.XD [/INST] \n",
            " NO\n",
            "</s> \n",
            "\n",
            " <s>[INST] Is the following TWEET sexist, in any form, or does it describe situations in which such discrimination occurs (i.e., it is sexist itself, describes a sexist situation or criticizes a sexist behaviour)? Reply only with YES or NO.\n",
            "TWEET:@Recuenco @qlopdopis Bannon also has history. Here they talk about him, good podcast, #16 - the winners of Gamergate https://t.co/nnfOHYhbrw [/INST] \n",
            " NO\n",
            "</s> \n",
            "\n",
            " \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Run!"
      ],
      "metadata": {
        "id": "r6Cqo0JqotN9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UKo1-X5OvT4b",
        "outputId": "88286136-1cd4-4244-f9ad-578a802d964a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<s>[INST] Is the following TWEET sexist, in any form, or does it describe situations in which such discrimination occurs (i.e., it is sexist itself, describes a sexist situation or criticizes a sexist behaviour)? Reply only with YES or NO.\n",
            "TWEET:@TheChiflis Ignore the other one, he's an idiot. The problem with this YouTuber is that he denounces harassment... when it doesn't affect people on the left. For example, in his video about gamergate he presents as \"normal\" the harassment that Fisher, Anita or Z√∂ey receive when there were even bomb threats. [/INST] \n",
            " YES\n",
            "</s> \n",
            "\n",
            " <s>[INST] Is the following TWEET sexist, in any form, or does it describe situations in which such discrimination occurs (i.e., it is sexist itself, describes a sexist situation or criticizes a sexist behaviour)? Reply only with YES or NO.\n",
            "TWEET:@ultimonomada_ If comicsgate is anything like gamergate, then good for the harassment. And if sabotage is being done because there are characters that you don't like, then thank you for agreeing with me. You are offended crybabies. [/INST] \n",
            " NO\n",
            "</s> \n",
            "\n",
            " <s>[INST] Is the following TWEET sexist, in any form, or does it describe situations in which such discrimination occurs (i.e., it is sexist itself, describes a sexist situation or criticizes a sexist behaviour)? Reply only with YES or NO.\n",
            "TWEET:@Steven2897 Read about Gamergate, and how it has changed the way we communicate on the internet. Halo fanboys are toxic but fanboys from other communities/games have also wanted to take a cue from that ü§∑üèæ‚Äç‚ôÇÔ∏è [/INST] \n",
            " NO\n",
            "</s> \n",
            "\n",
            " <s>[INST] Is the following TWEET sexist, in any form, or does it describe situations in which such discrimination occurs (i.e., it is sexist itself, describes a sexist situation or criticizes a sexist behaviour)? Reply only with YES or NO.\n",
            "TWEET:@novadragon21 @icep4ck @TvDannyZ So since this is the market, the best thing is not to do something to change it and continue feeding machismo in consumers instead of supporting people like the victims of gamergate. Regarding the other, the \"had\" implies a imperative then I don't understand what they were looking for. [/INST] \n",
            " YES\n",
            "</s> \n",
            "\n",
            " <s>[INST] Is the following TWEET sexist, in any form, or does it describe situations in which such discrimination occurs (i.e., it is sexist itself, describes a sexist situation or criticizes a sexist behaviour)? Reply only with YES or NO.\n",
            "TWEET:@yonkykong Aaah yes. Andrew Dobson. The one who dedicated himself to spouting gamergate shit in the purest white knight style, and all of deviantart fell on him [/INST] \n",
            " NO\n",
            "</s> \n",
            "\n",
            " <s>[INST] Is the following TWEET sexist, in any form, or does it describe situations in which such discrimination occurs (i.e., it is sexist itself, describes a sexist situation or criticizes a sexist behaviour)? Reply only with YES or NO.\n",
            "TWEET:@BestKabest This gringa is still crying about gamergate, what a \"coincidence\" that she has pronouns on her profile [/INST] \n",
            " YES\n",
            "</s> \n",
            "\n",
            " <s>[INST] Is the following TWEET sexist, in any form, or does it describe situations in which such discrimination occurs (i.e., it is sexist itself, describes a sexist situation or criticizes a sexist behaviour)? Reply only with YES or NO.\n",
            "TWEET:.Do you know the #GAMER #style #DECORATION for #teenagers? We explain it to you in our #post: ‚ù§Ô∏è https://t.co/NuSNs36GIT Are you following us? #inspiracionalcuadrado #interiorismo #homedecorideas #Madrid #chamberi #Salamanca #gamers #GAMERGATE #gamergirl https://t.co/Mcibiy8YdX [/INST] \n",
            " NO\n",
            "</s> \n",
            "\n",
            " <s>[INST] Is the following TWEET sexist, in any form, or does it describe situations in which such discrimination occurs (i.e., it is sexist itself, describes a sexist situation or criticizes a sexist behaviour)? Reply only with YES or NO.\n",
            "TWEET:CES 2022 ASUS ROG Rise of Gamers Launch Event https://t.co/CjqHQwxMFD #AMD2022 #AMD #AMDRedTeam #AMDRyzen #Intel #nvidia #NVIDIAOmniverse #NVIDIAGeForce #NVIDIAStudio #gamergirl #gamers #GamerGate #GamersUnite #gameroom #StockMarket # stocks #StocksToBuy #Stock [/INST] \n",
            " NO\n",
            "</s> \n",
            "\n",
            " <s>[INST] Is the following TWEET sexist, in any form, or does it describe situations in which such discrimination occurs (i.e., it is sexist itself, describes a sexist situation or criticizes a sexist behaviour)? Reply only with YES or NO.\n",
            "TWEET:@Lorebrou16 @arrobaDonko Shit, I feel old when you say Gamergate, what a bard .__.XD [/INST] \n",
            " NO\n",
            "</s> \n",
            "\n",
            " <s>[INST] Is the following TWEET sexist, in any form, or does it describe situations in which such discrimination occurs (i.e., it is sexist itself, describes a sexist situation or criticizes a sexist behaviour)? Reply only with YES or NO.\n",
            "TWEET:@Recuenco @qlopdopis Bannon also has history. Here they talk about him, good podcast, #16 - the winners of Gamergate https://t.co/nnfOHYhbrw [/INST] \n",
            " NO\n",
            "</s> \n",
            "\n",
            " [INST]\n",
            "@Eurogamer_es All gamergate from development to game forums, classic in the world of video games.\n",
            "[/INST]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1255.65 ms\n",
            "llama_print_timings:      sample time =       8.46 ms /    16 runs   (    0.53 ms per token,  1891.25 tokens per second)\n",
            "llama_print_timings: prompt eval time =       0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_print_timings:        eval time =    1872.72 ms /    16 runs   (  117.05 ms per token,     8.54 tokens per second)\n",
            "llama_print_timings:       total time =    1929.83 ms /    17 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'id': 'cmpl-a16a090f-b61b-4aa9-9d0c-a70eecb9f84b', 'object': 'text_completion', 'created': 1715252188, 'model': '/root/.cache/huggingface/hub/models--TheBloke--Mistral-7B-Instruct-v0.2-GGUF/snapshots/3a6fbf4a41a1d52e415a4958cde6856d34b2db93/mistral-7b-instruct-v0.2.Q6_K.gguf', 'choices': [{'text': ' \\n NO\\n\\nThis tweet does not contain any sexist language or', 'index': 0, 'logprobs': {'tokens': [' ', '\\n', ' NO', '\\n', '\\n', 'This', ' twe', 'et', ' does', ' not', ' contain', ' any', ' sex', 'ist', ' language', ' or'], 'text_offset': [4897, 4898, 4899, 4902, 4903, 4904, 4908, 4912, 4914, 4919, 4923, 4931, 4935, 4939, 4942, 4951], 'token_logprobs': [-0.27291778, -0.053139508, -0.0018108174, -0.10742129, -0.00057633, -1.4971123, -0.06931656, -3.5762778e-07, -0.40130493, -6.520536e-05, -0.09280562, -0.040356763, -0.10006745, -0.0005918181, -0.19531919, -0.038368657], 'top_logprobs': [{' ': -0.27291778}, {'\\n': -0.053139508}, {' NO': -0.0018108174}, {'\\n': -0.10742129}, {'\\n': -0.00057633}, {' ': -1.1819038, 'This': -1.4971123}, {' twe': -0.06931656}, {'et': -3.5762778e-07}, {' does': -0.40130493}, {' not': -6.520536e-05}, {' contain': -0.09280562}, {' any': -0.040356763}, {' sex': -0.10006745}, {'ist': -0.0005918181}, {' language': -0.19531919}, {' or': -0.038368657}]}, 'finish_reason': 'length'}], 'usage': {'prompt_tokens': 1484, 'completion_tokens': 16, 'total_tokens': 1500}}\n",
            "no\n",
            "\n",
            "this tweet does not contain any sexist language or\n",
            "GENERATED: [INST]\n",
            "@Eurogamer_es All gamergate from development to game forums, classic in the world of video games.\n",
            "[/INST]NO\n"
          ]
        }
      ],
      "source": [
        "replies_list = ['YES','NO']\n",
        "\n",
        "with open('answer.txt', 'w') as f:\n",
        "        f.write('')\n",
        "\n",
        "# simple JSON loading\n",
        "with open(test_path, 'r') as istr:\n",
        "    test_json = json.load(istr)\n",
        "num_sample = len(test_json)\n",
        "#print(num_sample)\n",
        "\n",
        "#print(train_1_json[0])\n",
        "for key, value in test_json.items():\n",
        "  tweet = test_json[key]['tweet']\n",
        "  if test_json[key]['lang']=='es':\n",
        "      tweet = GoogleTranslator(source='es', target='en').translate(test_json[key]['tweet'])\n",
        "\n",
        "  current_sample = '[INST]\\n'+tweet+'\\n[/INST]'\n",
        "  prompt = few_shot_samples+current_sample\n",
        "\n",
        "  print(prompt)\n",
        "\n",
        "  response = lcpp_llm(\n",
        "        prompt=prompt,\n",
        "        temperature= 0.2,\n",
        "        logprobs=1,\n",
        "        #max_tokens =1\n",
        "      )\n",
        "\n",
        "  print(response)\n",
        "\n",
        "  answer = str(response[\"choices\"][0][\"text\"]).strip().lower()\n",
        "  print(answer)\n",
        "  #answer = answer.split()[0]\n",
        "  # Sometime output contains a '.' remove it!\n",
        "  #answer = answer.replace('.','')\n",
        "\n",
        "  # If the predicted word is not in emotion list just replace with neutral.\n",
        "  if answer not in replies_list:\n",
        "        answer = 'NO'\n",
        "\n",
        "  #current_sample += answer + \" \\n \"\n",
        "\n",
        "  print(\"GENERATED: \"+ current_sample+answer)\n",
        "\n",
        "  with open('answer.txt', 'a') as f:\n",
        "    f.write(answer+\"\\n\")\n",
        "  break\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "counter=0\n",
        "for i in range(0,len(test_1_json)):\n",
        "  for sentence_nr in range(0,len(test_1_json[i]['utterances'])):\n",
        "    counter+=1\n",
        "\n",
        "print(counter)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "209aetruI4p0",
        "outputId": "7d8d6fa5-2040-4bde-dcce-bb74fa1f05bb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1580\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "open('newfile','w').writelines([ line for line in open('SemEval_2024_Task_10_Mistral7B_MSiino (1).ipynb') if 'GENERATED:' in line])\n",
        "\n",
        "result_not_filtered = [ line for line in open('SemEval_2024_Task_10_Mistral7B_MSiino (1).ipynb') if 'GENERATED:' in line]\n"
      ],
      "metadata": {
        "id": "VR-Z_ME9O6W0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('answer.txt', 'w') as f:\n",
        "        f.write('')"
      ],
      "metadata": {
        "id": "XkFIe4mNUPUI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('newfile') as f:\n",
        "   for line in f:\n",
        "       # For Python3, use print(line)\n",
        "       x = line.split()\n",
        "       result = x[len(x)-1].replace('\\\\n\",','')\n",
        "       result = result.replace('\\\\n\"','')\n",
        "       print (result)\n",
        "       with open('answer.txt', 'a') as f:\n",
        "        f.write(result+\"\\n\")"
      ],
      "metadata": {
        "id": "SzlBus5ZSM0C",
        "outputId": "9cc0c303-157e-4ed5-a85c-30fa5c95eecd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sadness\n",
            "neutral\n",
            "fear\n",
            "neutral\n",
            "anger\n",
            "disgust\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "disgust\n",
            "fear\n",
            "fear\n",
            "neutral\n",
            "neutral\n",
            "joy\n",
            "neutral\n",
            "neutral\n",
            "contempt\n",
            "joy\n",
            "neutral\n",
            "neutral\n",
            "sadness\n",
            "disgust\n",
            "fear\n",
            "surprise\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "disgust\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "joy\n",
            "joy\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "joy\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "fear\n",
            "joy\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "joy\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "fear\n",
            "disgust\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "sadness\n",
            "sadness\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "disgust\n",
            "neutral\n",
            "fear\n",
            "neutral\n",
            "neutral\n",
            "fear\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "anger\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "fear\n",
            "neutral\n",
            "fear\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "surprise\n",
            "neutral\n",
            "joy\n",
            "neutral\n",
            "neutral\n",
            "fear\n",
            "neutral\n",
            "neutral\n",
            "fear\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "fear\n",
            "fear\n",
            "neutral\n",
            "neutral\n",
            "joy\n",
            "neutral\n",
            "joy\n",
            "joy\n",
            "neutral\n",
            "joy\n",
            "neutral\n",
            "fear\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "fear\n",
            "neutral\n",
            "anger\n",
            "fear\n",
            "neutral\n",
            "neutral\n",
            "fear\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "anger\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "fear\n",
            "neutral\n",
            "neutral\n",
            "fear\n",
            "neutral\n",
            "fear\n",
            "neutral\n",
            "neutral\n",
            "fear\n",
            "anger\n",
            "neutral\n",
            "neutral\n",
            "disgust\n",
            "neutral\n",
            "neutral\n",
            "joy\n",
            "fear\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "disgust\n",
            "fear\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "fear\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "surprise\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "sadness\n",
            "neutral\n",
            "neutral\n",
            "joy\n",
            "neutral\n",
            "neutral\n",
            "fear\n",
            "neutral\n",
            "neutral\n",
            "joy\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "disgust\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "fear\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "fear\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "fear\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "sadness\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "sadness\n",
            "neutral\n",
            "neutral\n",
            "sadness\n",
            "fear\n",
            "disgust\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "joy\n",
            "neutral\n",
            "neutral\n",
            "joy\n",
            "neutral\n",
            "disgust\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "joy\n",
            "neutral\n",
            "neutral\n",
            "fear\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "fear\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "joy\n",
            "neutral\n",
            "joy\n",
            "fear\n",
            "neutral\n",
            "anger\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "disgust\n",
            "neutral\n",
            "disgust\n",
            "joy\n",
            "joy\n",
            "neutral\n",
            "disgust\n",
            "neutral\n",
            "disgust\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "fear\n",
            "neutral\n",
            "neutral\n",
            "fear\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "sadness\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "contempt\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "anger\n",
            "joy\n",
            "neutral\n",
            "fear\n",
            "joy\n",
            "joy\n",
            "disgust\n",
            "neutral\n",
            "disgust\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "sadness\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "fear\n",
            "sadness\n",
            "joy\n",
            "disgust\n",
            "joy\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "fear\n",
            "anger\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "contempt\n",
            "surprise\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "joy\n",
            "fear\n",
            "joy\n",
            "contempt\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "disgust\n",
            "fear\n",
            "sadness\n",
            "fear\n",
            "neutral\n",
            "disgust\n",
            "neutral\n",
            "neutral\n",
            "joy\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "disgust\n",
            "neutral\n",
            "joy\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "disgust\n",
            "neutral\n",
            "fear\n",
            "neutral\n",
            "disgust\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "disgust\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "sadness\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "disgust\n",
            "sadness\n",
            "joy\n",
            "sadness\n",
            "joy\n",
            "sadness\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "joy\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "sadness\n",
            "joy\n",
            "sadness\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "joy\n",
            "sadness\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "surprise\n",
            "neutral\n",
            "anger\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "disgust\n",
            "joy\n",
            "neutral\n",
            "sadness\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "joy\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "joy\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "joy\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "joy\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "sadness\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "joy\n",
            "joy\n",
            "neutral\n",
            "fear\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "fear\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "surprise\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "fear\n",
            "neutral\n",
            "fear\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "sadness\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "joy\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "fear\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "surprise\n",
            "disgust\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "fear\n",
            "neutral\n",
            "neutral\n",
            "fear\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "sadness\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "sadness\n",
            "sadness\n",
            "neutral\n",
            "joy\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "fear\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "disgust\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "joy\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "joy\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "joy\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "joy\n",
            "neutral\n",
            "neutral\n",
            "contempt\n",
            "joy\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "joy\n",
            "neutral\n",
            "joy\n",
            "neutral\n",
            "joy\n",
            "joy\n",
            "neutral\n",
            "neutral\n",
            "contempt\n",
            "neutral\n",
            "contempt\n",
            "neutral\n",
            "joy\n",
            "neutral\n",
            "contempt\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "disgust\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "joy\n",
            "fear\n",
            "neutral\n",
            "neutral\n",
            "fear\n",
            "disgust\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "fear\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "joy\n",
            "joy\n",
            "neutral\n",
            "surprise\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "joy\n",
            "neutral\n",
            "neutral\n",
            "joy\n",
            "joy\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "surprise\n",
            "neutral\n",
            "neutral\n",
            "disgust\n",
            "neutral\n",
            "neutral\n",
            "joy\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "disgust\n",
            "neutral\n",
            "neutral\n",
            "joy\n",
            "neutral\n",
            "joy\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "joy\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "anger\n",
            "joy\n",
            "joy\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "joy\n",
            "neutral\n",
            "neutral\n",
            "joy\n",
            "joy\n",
            "neutral\n",
            "neutral\n",
            "disgust\n",
            "joy\n",
            "neutral\n",
            "joy\n",
            "joy\n",
            "neutral\n",
            "sadness\n",
            "neutral\n",
            "joy\n",
            "contempt\n",
            "joy\n",
            "joy\n",
            "neutral\n",
            "neutral\n",
            "joy\n",
            "neutral\n",
            "neutral\n",
            "joy\n",
            "joy\n",
            "joy\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "disgust\n",
            "neutral\n",
            "neutral\n",
            "joy\n",
            "joy\n",
            "neutral\n",
            "sadness\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "joy\n",
            "joy\n",
            "joy\n",
            "neutral\n",
            "joy\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "joy\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "joy\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "fear\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "sadness\n",
            "neutral\n",
            "joy\n",
            "neutral\n",
            "joy\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "joy\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "joy\n",
            "joy\n",
            "joy\n",
            "joy\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "sadness\n",
            "neutral\n",
            "disgust\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "joy\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "joy\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "surprise\n",
            "neutral\n",
            "disgust\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "disgust\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "contempt\n",
            "neutral\n",
            "neutral\n",
            "joy\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "joy\n",
            "joy\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "fear\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "disgust\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "disgust\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "fear\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "joy\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "joy\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "joy\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "fear\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "disgust\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "joy\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "fear\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "fear\n",
            "joy\n",
            "neutral\n",
            "disgust\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "sadness\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "fear\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "surprise\n",
            "fear\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "fear\n",
            "neutral\n",
            "neutral\n",
            "joy\n",
            "neutral\n",
            "sadness\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "contempt\n",
            "contempt\n",
            "fear\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "disgust\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "fear\n",
            "neutral\n",
            "neutral\n",
            "joy\n",
            "neutral\n",
            "neutral\n",
            "sadness\n",
            "neutral\n",
            "neutral\n",
            "sadness\n",
            "neutral\n",
            "joy\n",
            "neutral\n",
            "surprise\n",
            "neutral\n",
            "neutral\n",
            "disgust\n",
            "fear\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "disgust\n",
            "neutral\n",
            "neutral\n",
            "fear\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "fear\n",
            "neutral\n",
            "fear\n",
            "sadness\n",
            "neutral\n",
            "neutral\n",
            "disgust\n",
            "surprise\n",
            "neutral\n",
            "joy\n",
            "neutral\n",
            "neutral\n",
            "joy\n",
            "surprise\n",
            "fear\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "sadness\n",
            "disgust\n",
            "neutral\n",
            "fear\n",
            "neutral\n",
            "neutral\n",
            "surprise\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "fear\n",
            "neutral\n",
            "fear\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "joy\n",
            "neutral\n",
            "surprise\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "fear\n",
            "joy\n",
            "neutral\n",
            "fear\n",
            "neutral\n",
            "neutral\n",
            "fear\n",
            "neutral\n",
            "fear\n",
            "neutral\n",
            "disgust\n",
            "sadness\n",
            "joy\n",
            "fear\n",
            "neutral\n",
            "neutral\n",
            "fear\n",
            "disgust\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "joy\n",
            "neutral\n",
            "joy\n",
            "joy\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "joy\n",
            "neutral\n",
            "contempt\n",
            "neutral\n",
            "surprise\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "disgust\n",
            "joy\n",
            "surprise\n",
            "neutral\n",
            "neutral\n",
            "joy\n",
            "neutral\n",
            "neutral\n",
            "joy\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "joy\n",
            "neutral\n",
            "joy\n",
            "neutral\n",
            "neutral\n",
            "joy\n",
            "fear\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "joy\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "fear\n",
            "disgust\n",
            "neutral\n",
            "disgust\n",
            "contempt\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "contempt\n",
            "joy\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "sadness\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "sadness\n",
            "neutral\n",
            "neutral\n",
            "disgust\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "disgust\n",
            "disgust\n",
            "joy\n",
            "joy\n",
            "neutral\n",
            "neutral\n",
            "joy\n",
            "joy\n",
            "neutral\n",
            "joy\n",
            "joy\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "joy\n",
            "joy\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "joy\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "sadness\n",
            "neutral\n",
            "neutral\n",
            "joy\n",
            "neutral\n",
            "joy\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "disgust\n",
            "fear\n",
            "fear\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "fear\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "fear\n",
            "neutral\n",
            "fear\n",
            "neutral\n",
            "fear\n",
            "fear\n",
            "fear\n",
            "fear\n",
            "fear\n",
            "neutral\n",
            "anger\n",
            "contempt\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "anger\n",
            "anger\n",
            "neutral\n",
            "joy\n",
            "fear\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "fear\n",
            "neutral\n",
            "anger\n",
            "anger\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "anger\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "joy\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "anger\n",
            "neutral\n",
            "joy\n",
            "neutral\n",
            "joy\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "fear\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "fear\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "sadness\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "disgust\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "neutral\n",
            "surprise\n",
            "joy\n",
            "neutral\n",
            "current_sample+answer)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Now fill the remaining lines for the other two tasks.\n",
        "\n",
        "for i in range(1581,17913):\n",
        "  r_int_value = random.randint(0, 1)\n",
        "  r_string_value = str(r_int_value)+'.0'\n",
        "  with open('answer.txt', 'a') as f:\n",
        "        f.write(r_string_value+\"\\n\")\n"
      ],
      "metadata": {
        "id": "vFIWPRbu94e8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r results.zip answer.txt"
      ],
      "metadata": {
        "id": "JAUcpxAdivmY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1649bd0e-3706-4513-ee96-d40b0061e3ce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: answer.txt (deflated 94%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download('results.zip')"
      ],
      "metadata": {
        "id": "dia3xJw7TwSL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "4c132f11-547a-414d-f7fa-fbe838eb1735"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_4d855f4e-51a6-4ae4-a1e9-bf6dd792fe0d\", \"results.zip\", 4729)"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "2f9ce44597fd4605ae80a651595427b8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e3b28ef3d43f485eab6249e38bce939d",
              "IPY_MODEL_422514713b674c6fa08e3ccfec13d587",
              "IPY_MODEL_f1af885bd06a414194141b2b4caba3c5"
            ],
            "layout": "IPY_MODEL_bcd7b0cb09fd4011817744131ed5786b"
          }
        },
        "e3b28ef3d43f485eab6249e38bce939d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ecc8fceff5be4c74a8e8078c30a0537e",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_066a845b3b494ffc86eaf3b42f4f1be8",
            "value": "mistral-7b-instruct-v0.2.Q6_K.gguf:‚Äá100%"
          }
        },
        "422514713b674c6fa08e3ccfec13d587": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8a17530926d34ebc81cf106d8a1a1892",
            "max": 5942065440,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ee360156296d477ead496a7516f8c40b",
            "value": 5942065440
          }
        },
        "f1af885bd06a414194141b2b4caba3c5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_00742ad8442849b7884fc2771237645e",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_4fd3deff3d1f40b693b7c2722c1cc959",
            "value": "‚Äá5.94G/5.94G‚Äá[00:44&lt;00:00,‚Äá121MB/s]"
          }
        },
        "bcd7b0cb09fd4011817744131ed5786b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ecc8fceff5be4c74a8e8078c30a0537e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "066a845b3b494ffc86eaf3b42f4f1be8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8a17530926d34ebc81cf106d8a1a1892": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ee360156296d477ead496a7516f8c40b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "00742ad8442849b7884fc2771237645e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4fd3deff3d1f40b693b7c2722c1cc959": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}